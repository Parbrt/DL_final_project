{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-17T09:53:58.151505Z",
     "start_time": "2025-12-17T09:52:35.806620Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "X_train = pd.read_csv('../data/processed/X_train.csv')\n",
    "X_test = pd.read_csv('../data/processed/X_test.csv')\n",
    "y_train_reg = pd.read_csv('../data/processed/y_train_reg.csv')\n",
    "y_test_reg = pd.read_csv('../data/processed/y_test_reg.csv')\n",
    "\n",
    "n_col = X_train.shape[1]\n",
    "model_regressor = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(n_col,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "\n",
    "    tf.keras.layers.Dense(2, activation='linear')\n",
    "])\n",
    "\n",
    "model_regressor.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                        loss='mse',\n",
    "                        metrics=['mae'])\n",
    "\n",
    "start_training = time.time()\n",
    "history = model_regressor.fit(\n",
    "    X_train, y_train_reg,\n",
    "    validation_split=0.2,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")\n",
    "end_training = time.time() - start_training\n",
    "print(f\"Temps d'entraînement : {end_training:.2f} secondes\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001B[1m1225/1225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 3ms/step - loss: 52491328.0000 - mae: 3826.9131 - val_loss: 40225928.0000 - val_mae: 3185.3684\n",
      "Epoch 2/20\n",
      "\u001B[1m1225/1225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 3ms/step - loss: 38385852.0000 - mae: 3145.2424 - val_loss: 30544280.0000 - val_mae: 2689.2085\n",
      "Epoch 3/20\n",
      "\u001B[1m1225/1225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 3ms/step - loss: 32321788.0000 - mae: 2806.5986 - val_loss: 25753636.0000 - val_mae: 2471.0474\n",
      "Epoch 4/20\n",
      "\u001B[1m1225/1225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 3ms/step - loss: 28872574.0000 - mae: 2604.3687 - val_loss: 23916812.0000 - val_mae: 2261.0308\n",
      "Epoch 5/20\n",
      "\u001B[1m1225/1225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 3ms/step - loss: 27059440.0000 - mae: 2499.4578 - val_loss: 22061844.0000 - val_mae: 2260.7764\n",
      "Epoch 6/20\n",
      "\u001B[1m1225/1225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 3ms/step - loss: 26182890.0000 - mae: 2431.9692 - val_loss: 22520776.0000 - val_mae: 2172.7051\n",
      "Epoch 7/20\n",
      "\u001B[1m1225/1225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 3ms/step - loss: 25247228.0000 - mae: 2376.2141 - val_loss: 21546152.0000 - val_mae: 2105.4050\n",
      "Epoch 8/20\n",
      "\u001B[1m1225/1225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 3ms/step - loss: 25090552.0000 - mae: 2352.2981 - val_loss: 20737098.0000 - val_mae: 2151.9175\n",
      "Epoch 9/20\n",
      "\u001B[1m1225/1225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - loss: 24453562.0000 - mae: 2320.8000 - val_loss: 21062330.0000 - val_mae: 2108.6624\n",
      "Epoch 10/20\n",
      "\u001B[1m1225/1225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 3ms/step - loss: 24066148.0000 - mae: 2291.7827 - val_loss: 20536794.0000 - val_mae: 2065.1931\n",
      "Epoch 11/20\n",
      "\u001B[1m1225/1225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 3ms/step - loss: 23675532.0000 - mae: 2277.9238 - val_loss: 20198018.0000 - val_mae: 2191.5598\n",
      "Epoch 12/20\n",
      "\u001B[1m1225/1225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 3ms/step - loss: 23492232.0000 - mae: 2273.2388 - val_loss: 19491756.0000 - val_mae: 2078.7571\n",
      "Epoch 13/20\n",
      "\u001B[1m1225/1225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 3ms/step - loss: 23305824.0000 - mae: 2263.9109 - val_loss: 20223438.0000 - val_mae: 2043.8932\n",
      "Epoch 14/20\n",
      "\u001B[1m1225/1225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 3ms/step - loss: 22812340.0000 - mae: 2234.1733 - val_loss: 25881742.0000 - val_mae: 2218.8682\n",
      "Epoch 15/20\n",
      "\u001B[1m1225/1225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 3ms/step - loss: 23026908.0000 - mae: 2244.9197 - val_loss: 21151104.0000 - val_mae: 2268.2083\n",
      "Epoch 16/20\n",
      "\u001B[1m1225/1225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 3ms/step - loss: 22873420.0000 - mae: 2240.0859 - val_loss: 25164506.0000 - val_mae: 2170.8357\n",
      "Epoch 17/20\n",
      "\u001B[1m1225/1225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 3ms/step - loss: 22570096.0000 - mae: 2227.0928 - val_loss: 21844510.0000 - val_mae: 2067.1450\n",
      "Epoch 18/20\n",
      "\u001B[1m1225/1225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 3ms/step - loss: 22516308.0000 - mae: 2221.5947 - val_loss: 23749538.0000 - val_mae: 2137.5818\n",
      "Epoch 19/20\n",
      "\u001B[1m1225/1225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 3ms/step - loss: 22452096.0000 - mae: 2213.8303 - val_loss: 19480170.0000 - val_mae: 2105.1865\n",
      "Epoch 20/20\n",
      "\u001B[1m1225/1225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 3ms/step - loss: 22631742.0000 - mae: 2221.0396 - val_loss: 20174932.0000 - val_mae: 2130.8643\n",
      "Temps d'entraînement : 81.25 secondes\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T09:55:21.767766Z",
     "start_time": "2025-12-17T09:55:15.141272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "y_pred_train = model_regressor.predict(X_train, verbose=0)\n",
    "\n",
    "start_pred = time.time()\n",
    "y_pred_test = model_regressor.predict(X_test, verbose=0)\n",
    "end_pred = time.time() - start_pred\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train_reg, y_pred_train))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred_test))\n",
    "\n",
    "train_mae = mean_absolute_error(y_train_reg, y_pred_train)\n",
    "test_mae = mean_absolute_error(y_test_reg, y_pred_test)\n",
    "\n",
    "\n",
    "print(f\"pred test: {end_pred:.4f} s\")\n",
    "print(f\"Train RMSE : {train_rmse:.2f}\")\n",
    "print(f\"Test RMSE  : {test_rmse:.2f} ss \")\n",
    "print(f\"Train MAE  : {train_mae:.2f}\")\n",
    "print(f\"Test MAE   : {test_mae:.2f}\")\n"
   ],
   "id": "6f90703855defdf8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Temps de prédiction (Test): 1.3686 s\n",
      "------------------------------\n",
      "Train RMSE : 4514.66\n",
      "Test RMSE  : 4505.22 ss \n",
      "------------------------------\n",
      "Train MAE  : 2140.08\n",
      "Test MAE   : 2129.34\n",
      "------------------------------\n",
      "✅ Excellent : Pas d'overfitting (ou Dropout efficace).\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
