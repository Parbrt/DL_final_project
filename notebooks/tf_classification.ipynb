{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-17T15:40:34.057599Z",
     "start_time": "2025-12-17T15:40:32.084641Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "X_train = pd.read_csv('../data/processed/X_train.csv')\n",
    "X_test = pd.read_csv('../data/processed/X_test.csv')\n",
    "y_train_cat = pd.read_csv('../data/processed/y_train_cat.csv')\n",
    "y_test_cat = pd.read_csv('../data/processed/y_test_cat.csv')"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T15:41:32.217172Z",
     "start_time": "2025-12-17T15:40:34.115170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "n_col = X_train.shape[1]\n",
    "model_classifier = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(n_col,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu',\n",
    "                              kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "        tf.keras.layers.Dense(32, activation='relu',\n",
    "                              kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "model_classifier.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "history = model_classifier.fit(\n",
    "        X_train, y_train_cat,\n",
    "        validation_split=0.2,\n",
    "        epochs=15,\n",
    "        batch_size=64,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "y_pred_prob = model_classifier.predict(X_test)\n",
    "loss, accuracy = model_classifier.evaluate(X_test, y_test_cat, verbose=0)\n",
    "auc = roc_auc_score(y_test_cat, y_pred_prob)\n",
    "\n",
    "print(f\"   Accuracy : {accuracy:.2%}\")\n",
    "print(f\"   AUC      : {auc:.4f}\")\n",
    "print(f\"   Loss     : {loss:.4f}\")"
   ],
   "id": "ea0ed2b527159110",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m766/766\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "   Accuracy : 74.46%\n",
      "   AUC      : 0.8414\n",
      "   Loss     : 0.5238\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T16:12:16.538843Z",
     "start_time": "2025-12-17T15:41:32.280983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import optuna\n",
    "\n",
    "\n",
    "def objective_classification(trial):\n",
    "    activation_chosen = trial.suggest_categorical('activation', ['relu', 'elu', 'swish'])\n",
    "    units_1 = trial.suggest_int('units_1', 16, 100)\n",
    "    units_2 = trial.suggest_int('units_2', 16, 100)\n",
    "    dropout_rate_1 = trial.suggest_float('dropout_rate_1', 0.0, 0.5)\n",
    "    dropout_rate_2 = trial.suggest_float('dropout_rate_2', 0.1, 0.5)\n",
    "    l2_reg = trial.suggest_float('l2_reg', 0.00001, 0.01, log=True)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.0001, 0.01, log=True)\n",
    "\n",
    "    n_col = X_train.shape[1]\n",
    "    model_classifier_opti = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(n_col,)),\n",
    "        tf.keras.layers.Dense(units_1, activation=activation_chosen, kernel_regularizer=tf.keras.regularizers.l2(l2_reg)),\n",
    "        tf.keras.layers.Dropout(dropout_rate_1),\n",
    "\n",
    "        tf.keras.layers.Dense(units_2, activation=activation_chosen, kernel_regularizer=tf.keras.regularizers.l2(l2_reg)),\n",
    "        tf.keras.layers.Dropout(dropout_rate_2),\n",
    "\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model_classifier_opti.compile(\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss = 'binary_crossentropy',\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    history = model_classifier_opti.fit(\n",
    "        X_train, y_train_cat,\n",
    "        validation_split=0.2,\n",
    "        epochs=15,\n",
    "        batch_size=64,\n",
    "        verbose=0\n",
    "    )\n",
    "    return history.history['val_loss'][-1]\n",
    "\n",
    "storage_name = \"sqlite:///../db.sqlite3\"\n",
    "study = optuna.create_study(\n",
    "    study_name=\"optimization_winner\",\n",
    "    storage=storage_name,\n",
    "    direction='minimize',\n",
    "    load_if_exists=True\n",
    ")\n",
    "study.optimize(objective_classification, n_trials=30)\n",
    "print(f\"Best loss :{study.best_value}\")\n",
    "print(f\"Meilleur hyperparametres: {study.best_params}\")"
   ],
   "id": "8573870406dd7bbf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jevsez\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-12-17 16:41:33,625] A new study created in RDB with name: optimization_winner\n",
      "[I 2025-12-17 16:42:26,447] Trial 0 finished with value: 0.4718772768974304 and parameters: {'activation': 'relu', 'units_1': 17, 'units_2': 17, 'dropout_rate_1': 0.4325303059921805, 'dropout_rate_2': 0.15131994276965172, 'l2_reg': 0.0003356917114802452, 'learning_rate': 0.0017442382553700883}. Best is trial 0 with value: 0.4718772768974304.\n",
      "[I 2025-12-17 16:43:22,378] Trial 1 finished with value: 0.5435472726821899 and parameters: {'activation': 'elu', 'units_1': 44, 'units_2': 91, 'dropout_rate_1': 0.3697713432270313, 'dropout_rate_2': 0.38292973978477296, 'l2_reg': 0.007251826427343721, 'learning_rate': 0.00810328606972994}. Best is trial 0 with value: 0.4718772768974304.\n",
      "[I 2025-12-17 16:44:26,881] Trial 2 finished with value: 0.4904896020889282 and parameters: {'activation': 'swish', 'units_1': 100, 'units_2': 64, 'dropout_rate_1': 0.3323072050344977, 'dropout_rate_2': 0.18011137174994443, 'l2_reg': 0.0029385004982390448, 'learning_rate': 0.0015123618823040654}. Best is trial 0 with value: 0.4718772768974304.\n",
      "[I 2025-12-17 16:45:23,246] Trial 3 finished with value: 0.4650275409221649 and parameters: {'activation': 'elu', 'units_1': 42, 'units_2': 92, 'dropout_rate_1': 0.47855447041006227, 'dropout_rate_2': 0.19466878761661954, 'l2_reg': 0.00023962545499210208, 'learning_rate': 0.000709092001052232}. Best is trial 3 with value: 0.4650275409221649.\n",
      "[I 2025-12-17 16:46:19,744] Trial 4 finished with value: 0.4712691307067871 and parameters: {'activation': 'relu', 'units_1': 85, 'units_2': 54, 'dropout_rate_1': 0.160875753614712, 'dropout_rate_2': 0.3402093457550193, 'l2_reg': 8.789793702817474e-05, 'learning_rate': 0.006376102846455098}. Best is trial 3 with value: 0.4650275409221649.\n",
      "[I 2025-12-17 16:47:20,514] Trial 5 finished with value: 0.4868262708187103 and parameters: {'activation': 'elu', 'units_1': 94, 'units_2': 48, 'dropout_rate_1': 0.10778614875359604, 'dropout_rate_2': 0.25726742558143717, 'l2_reg': 0.0002887590110849562, 'learning_rate': 0.006755413857303256}. Best is trial 3 with value: 0.4650275409221649.\n",
      "[I 2025-12-17 16:48:17,535] Trial 6 finished with value: 0.4969203770160675 and parameters: {'activation': 'elu', 'units_1': 66, 'units_2': 46, 'dropout_rate_1': 0.09313033016030375, 'dropout_rate_2': 0.3638957850693356, 'l2_reg': 0.004573170736086342, 'learning_rate': 0.0027087167330842503}. Best is trial 3 with value: 0.4650275409221649.\n",
      "[I 2025-12-17 16:49:14,355] Trial 7 finished with value: 0.48964691162109375 and parameters: {'activation': 'elu', 'units_1': 77, 'units_2': 49, 'dropout_rate_1': 0.4862706651042057, 'dropout_rate_2': 0.21229285588478405, 'l2_reg': 0.0005323361359791699, 'learning_rate': 0.0040670265080310335}. Best is trial 3 with value: 0.4650275409221649.\n",
      "[I 2025-12-17 16:50:17,094] Trial 8 finished with value: 0.4736573398113251 and parameters: {'activation': 'swish', 'units_1': 27, 'units_2': 63, 'dropout_rate_1': 0.14595156718669028, 'dropout_rate_2': 0.13976550160882262, 'l2_reg': 0.0008923821737175625, 'learning_rate': 0.0033886819341903333}. Best is trial 3 with value: 0.4650275409221649.\n",
      "[I 2025-12-17 16:51:30,543] Trial 9 finished with value: 0.44942507147789 and parameters: {'activation': 'swish', 'units_1': 78, 'units_2': 81, 'dropout_rate_1': 0.06289380801381755, 'dropout_rate_2': 0.3330825354892202, 'l2_reg': 5.919995051182718e-05, 'learning_rate': 0.000455246917584884}. Best is trial 9 with value: 0.44942507147789.\n",
      "[I 2025-12-17 16:52:47,907] Trial 10 finished with value: 0.4513026475906372 and parameters: {'activation': 'swish', 'units_1': 63, 'units_2': 78, 'dropout_rate_1': 0.004992889215272689, 'dropout_rate_2': 0.47637219628355076, 'l2_reg': 1.1466106753810796e-05, 'learning_rate': 0.00016135964911881854}. Best is trial 9 with value: 0.44942507147789.\n",
      "[I 2025-12-17 16:53:55,489] Trial 11 finished with value: 0.4523698091506958 and parameters: {'activation': 'swish', 'units_1': 63, 'units_2': 78, 'dropout_rate_1': 0.006953417862321766, 'dropout_rate_2': 0.480093134579959, 'l2_reg': 1.0370805886716747e-05, 'learning_rate': 0.00016976300831097527}. Best is trial 9 with value: 0.44942507147789.\n",
      "[I 2025-12-17 16:55:05,408] Trial 12 finished with value: 0.44952139258384705 and parameters: {'activation': 'swish', 'units_1': 72, 'units_2': 78, 'dropout_rate_1': 0.027691131127228624, 'dropout_rate_2': 0.48948783392528483, 'l2_reg': 1.3882638905787866e-05, 'learning_rate': 0.00019265414709069878}. Best is trial 9 with value: 0.44942507147789.\n",
      "[I 2025-12-17 16:56:12,530] Trial 13 finished with value: 0.450281023979187 and parameters: {'activation': 'swish', 'units_1': 78, 'units_2': 78, 'dropout_rate_1': 0.2445938796475535, 'dropout_rate_2': 0.4254009727315931, 'l2_reg': 4.2158249492978576e-05, 'learning_rate': 0.0004513511765214671}. Best is trial 9 with value: 0.44942507147789.\n",
      "[I 2025-12-17 16:57:18,818] Trial 14 finished with value: 0.44765153527259827 and parameters: {'activation': 'swish', 'units_1': 52, 'units_2': 100, 'dropout_rate_1': 0.05893895306750356, 'dropout_rate_2': 0.2824800918058621, 'l2_reg': 3.3422588753258134e-05, 'learning_rate': 0.0003236092840183618}. Best is trial 14 with value: 0.44765153527259827.\n",
      "[I 2025-12-17 16:58:25,721] Trial 15 finished with value: 0.4548202455043793 and parameters: {'activation': 'swish', 'units_1': 50, 'units_2': 100, 'dropout_rate_1': 0.22841826678588048, 'dropout_rate_2': 0.28808343111014045, 'l2_reg': 6.243660269981499e-05, 'learning_rate': 0.00035912832206459695}. Best is trial 14 with value: 0.44765153527259827.\n",
      "[I 2025-12-17 16:59:30,846] Trial 16 finished with value: 0.44954928755760193 and parameters: {'activation': 'swish', 'units_1': 53, 'units_2': 99, 'dropout_rate_1': 0.07986274283408462, 'dropout_rate_2': 0.2519587714329626, 'l2_reg': 3.29611488831946e-05, 'learning_rate': 0.000362803440094838}. Best is trial 14 with value: 0.44765153527259827.\n",
      "[I 2025-12-17 17:00:27,712] Trial 17 finished with value: 0.4640956521034241 and parameters: {'activation': 'relu', 'units_1': 34, 'units_2': 88, 'dropout_rate_1': 0.18117849549497367, 'dropout_rate_2': 0.3165793074011368, 'l2_reg': 0.0001232507001204185, 'learning_rate': 0.00010455757065018938}. Best is trial 14 with value: 0.44765153527259827.\n",
      "[I 2025-12-17 17:01:31,295] Trial 18 finished with value: 0.44766655564308167 and parameters: {'activation': 'swish', 'units_1': 85, 'units_2': 32, 'dropout_rate_1': 0.31474061832610556, 'dropout_rate_2': 0.42621107463735636, 'l2_reg': 2.7031102336851222e-05, 'learning_rate': 0.000738728347731789}. Best is trial 14 with value: 0.44765153527259827.\n",
      "[I 2025-12-17 17:02:32,757] Trial 19 finished with value: 0.44783464074134827 and parameters: {'activation': 'swish', 'units_1': 87, 'units_2': 24, 'dropout_rate_1': 0.3043431464013427, 'dropout_rate_2': 0.41632881988095527, 'l2_reg': 2.7598448658012796e-05, 'learning_rate': 0.0008064946733414997}. Best is trial 14 with value: 0.44765153527259827.\n",
      "[I 2025-12-17 17:03:28,957] Trial 20 finished with value: 0.44548046588897705 and parameters: {'activation': 'relu', 'units_1': 58, 'units_2': 36, 'dropout_rate_1': 0.3032199020479227, 'dropout_rate_2': 0.42885563131173265, 'l2_reg': 2.5001842095147902e-05, 'learning_rate': 0.0013225623606077923}. Best is trial 20 with value: 0.44548046588897705.\n",
      "[I 2025-12-17 17:04:25,191] Trial 21 finished with value: 0.4465058445930481 and parameters: {'activation': 'relu', 'units_1': 53, 'units_2': 35, 'dropout_rate_1': 0.2993178225688774, 'dropout_rate_2': 0.427659367842195, 'l2_reg': 2.1567519348966107e-05, 'learning_rate': 0.0013095882273212107}. Best is trial 20 with value: 0.44548046588897705.\n",
      "[I 2025-12-17 17:05:20,277] Trial 22 finished with value: 0.44569462537765503 and parameters: {'activation': 'relu', 'units_1': 56, 'units_2': 36, 'dropout_rate_1': 0.385739651695583, 'dropout_rate_2': 0.10197346205536312, 'l2_reg': 2.078779838610261e-05, 'learning_rate': 0.0012917083928493127}. Best is trial 20 with value: 0.44548046588897705.\n",
      "[I 2025-12-17 17:06:17,343] Trial 23 finished with value: 0.45103904604911804 and parameters: {'activation': 'relu', 'units_1': 58, 'units_2': 35, 'dropout_rate_1': 0.39423100413584367, 'dropout_rate_2': 0.11024292910507312, 'l2_reg': 1.6302856616331763e-05, 'learning_rate': 0.0013500712013491476}. Best is trial 20 with value: 0.44548046588897705.\n",
      "[I 2025-12-17 17:07:12,865] Trial 24 finished with value: 0.45812302827835083 and parameters: {'activation': 'relu', 'units_1': 42, 'units_2': 37, 'dropout_rate_1': 0.27912963980801025, 'dropout_rate_2': 0.38627667813173205, 'l2_reg': 0.00013112508038286822, 'learning_rate': 0.0024350810582527953}. Best is trial 20 with value: 0.44548046588897705.\n",
      "[I 2025-12-17 17:08:18,183] Trial 25 finished with value: 0.44790419936180115 and parameters: {'activation': 'relu', 'units_1': 34, 'units_2': 28, 'dropout_rate_1': 0.3557729680774564, 'dropout_rate_2': 0.45585173634709625, 'l2_reg': 1.8538345421874085e-05, 'learning_rate': 0.001149534757862053}. Best is trial 20 with value: 0.44548046588897705.\n",
      "[I 2025-12-17 17:09:16,132] Trial 26 finished with value: 0.4549512267112732 and parameters: {'activation': 'relu', 'units_1': 56, 'units_2': 40, 'dropout_rate_1': 0.4095348389003806, 'dropout_rate_2': 0.38840668399283523, 'l2_reg': 5.8040625677351434e-05, 'learning_rate': 0.0020873675952388085}. Best is trial 20 with value: 0.44548046588897705.\n",
      "[I 2025-12-17 17:10:15,642] Trial 27 finished with value: 0.4452647864818573 and parameters: {'activation': 'relu', 'units_1': 70, 'units_2': 16, 'dropout_rate_1': 0.20919892048363387, 'dropout_rate_2': 0.44724275744610087, 'l2_reg': 2.0239547386813323e-05, 'learning_rate': 0.0009850649524323052}. Best is trial 27 with value: 0.4452647864818573.\n",
      "[I 2025-12-17 17:11:15,980] Trial 28 finished with value: 0.46507805585861206 and parameters: {'activation': 'relu', 'units_1': 71, 'units_2': 18, 'dropout_rate_1': 0.20789045202921175, 'dropout_rate_2': 0.4614279321641852, 'l2_reg': 0.0013014598038857354, 'learning_rate': 0.0009319905804983767}. Best is trial 27 with value: 0.4452647864818573.\n",
      "[I 2025-12-17 17:12:16,530] Trial 29 finished with value: 0.4558022916316986 and parameters: {'activation': 'relu', 'units_1': 66, 'units_2': 16, 'dropout_rate_1': 0.45276584248983276, 'dropout_rate_2': 0.2451634669034607, 'l2_reg': 0.00013818062885702514, 'learning_rate': 0.0018203846769891258}. Best is trial 27 with value: 0.4452647864818573.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss :0.4452647864818573\n",
      "Meilleur hyperparametres: {'activation': 'relu', 'units_1': 70, 'units_2': 16, 'dropout_rate_1': 0.20919892048363387, 'dropout_rate_2': 0.44724275744610087, 'l2_reg': 2.0239547386813323e-05, 'learning_rate': 0.0009850649524323052}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T16:20:38.602941Z",
     "start_time": "2025-12-17T16:12:16.718232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "best = study.best_params\n",
    "\n",
    "model_final = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "\n",
    "    tf.keras.layers.Dense(best['units_1'], activation=best['activation'],\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(best['l2_reg'])),\n",
    "    tf.keras.layers.Dropout(best['dropout_rate_1']),\n",
    "\n",
    "    tf.keras.layers.Dense(best['units_2'], activation=best['activation'],\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(best['l2_reg'])),\n",
    "    tf.keras.layers.Dropout(best['dropout_rate_2']),\n",
    "\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_final.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=best['learning_rate']),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "\n",
    "history_final = model_final.fit(\n",
    "    X_train, y_train_cat,\n",
    "    validation_split=0.2,\n",
    "    epochs=60,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "y_pred_prob = model_final.predict(X_test)\n",
    "y_pred_class = (y_pred_prob > 0.5).astype(int)\n",
    "loss, accuracy, auc_keras = model_final.evaluate(X_test, y_test_cat, verbose=0)\n",
    "auc_score = roc_auc_score(y_test_cat, y_pred_prob)\n",
    "\n",
    "print(f\"Accuracy : {accuracy:.2%}\")\n",
    "print(f\"AUC ROC  : {auc_score:.4f}\")\n",
    "print(f\"Loss     : {loss:.4f}\")"
   ],
   "id": "e04ded9f76479700",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 3ms/step - accuracy: 0.7281 - auc: 0.8213 - loss: 0.5103 - val_accuracy: 0.7493 - val_auc: 0.8541 - val_loss: 0.4617\n",
      "Epoch 2/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 4ms/step - accuracy: 0.7444 - auc: 0.8433 - loss: 0.4783 - val_accuracy: 0.7547 - val_auc: 0.8575 - val_loss: 0.4575\n",
      "Epoch 3/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 4ms/step - accuracy: 0.7509 - auc: 0.8497 - loss: 0.4711 - val_accuracy: 0.7515 - val_auc: 0.8574 - val_loss: 0.4554\n",
      "Epoch 4/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7510 - auc: 0.8512 - loss: 0.4684 - val_accuracy: 0.7550 - val_auc: 0.8605 - val_loss: 0.4506\n",
      "Epoch 5/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7526 - auc: 0.8530 - loss: 0.4658 - val_accuracy: 0.7593 - val_auc: 0.8608 - val_loss: 0.4520\n",
      "Epoch 6/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7549 - auc: 0.8550 - loss: 0.4613 - val_accuracy: 0.7569 - val_auc: 0.8606 - val_loss: 0.4498\n",
      "Epoch 7/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7542 - auc: 0.8558 - loss: 0.4611 - val_accuracy: 0.7575 - val_auc: 0.8617 - val_loss: 0.4508\n",
      "Epoch 8/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7564 - auc: 0.8567 - loss: 0.4592 - val_accuracy: 0.7586 - val_auc: 0.8626 - val_loss: 0.4477\n",
      "Epoch 9/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7567 - auc: 0.8580 - loss: 0.4568 - val_accuracy: 0.7576 - val_auc: 0.8641 - val_loss: 0.4480\n",
      "Epoch 10/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7577 - auc: 0.8588 - loss: 0.4564 - val_accuracy: 0.7589 - val_auc: 0.8635 - val_loss: 0.4474\n",
      "Epoch 11/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7576 - auc: 0.8596 - loss: 0.4541 - val_accuracy: 0.7581 - val_auc: 0.8637 - val_loss: 0.4474\n",
      "Epoch 12/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7597 - auc: 0.8608 - loss: 0.4533 - val_accuracy: 0.7611 - val_auc: 0.8648 - val_loss: 0.4462\n",
      "Epoch 13/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7611 - auc: 0.8614 - loss: 0.4525 - val_accuracy: 0.7579 - val_auc: 0.8642 - val_loss: 0.4454\n",
      "Epoch 14/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7592 - auc: 0.8611 - loss: 0.4520 - val_accuracy: 0.7614 - val_auc: 0.8653 - val_loss: 0.4442\n",
      "Epoch 15/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7602 - auc: 0.8623 - loss: 0.4500 - val_accuracy: 0.7593 - val_auc: 0.8646 - val_loss: 0.4460\n",
      "Epoch 16/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7618 - auc: 0.8633 - loss: 0.4493 - val_accuracy: 0.7621 - val_auc: 0.8657 - val_loss: 0.4435\n",
      "Epoch 17/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7629 - auc: 0.8641 - loss: 0.4483 - val_accuracy: 0.7629 - val_auc: 0.8659 - val_loss: 0.4424\n",
      "Epoch 18/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7621 - auc: 0.8638 - loss: 0.4484 - val_accuracy: 0.7610 - val_auc: 0.8660 - val_loss: 0.4436\n",
      "Epoch 19/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7608 - auc: 0.8641 - loss: 0.4476 - val_accuracy: 0.7626 - val_auc: 0.8664 - val_loss: 0.4434\n",
      "Epoch 20/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7628 - auc: 0.8656 - loss: 0.4449 - val_accuracy: 0.7619 - val_auc: 0.8662 - val_loss: 0.4434\n",
      "Epoch 21/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7636 - auc: 0.8658 - loss: 0.4458 - val_accuracy: 0.7619 - val_auc: 0.8666 - val_loss: 0.4437\n",
      "Epoch 22/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 4ms/step - accuracy: 0.7645 - auc: 0.8662 - loss: 0.4456 - val_accuracy: 0.7624 - val_auc: 0.8671 - val_loss: 0.4429\n",
      "Epoch 23/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7645 - auc: 0.8668 - loss: 0.4445 - val_accuracy: 0.7624 - val_auc: 0.8677 - val_loss: 0.4421\n",
      "Epoch 24/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7649 - auc: 0.8668 - loss: 0.4450 - val_accuracy: 0.7637 - val_auc: 0.8672 - val_loss: 0.4406\n",
      "Epoch 25/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 3ms/step - accuracy: 0.7668 - auc: 0.8684 - loss: 0.4428 - val_accuracy: 0.7643 - val_auc: 0.8679 - val_loss: 0.4420\n",
      "Epoch 26/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 4ms/step - accuracy: 0.7648 - auc: 0.8675 - loss: 0.4431 - val_accuracy: 0.7663 - val_auc: 0.8678 - val_loss: 0.4427\n",
      "Epoch 27/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7653 - auc: 0.8683 - loss: 0.4420 - val_accuracy: 0.7639 - val_auc: 0.8669 - val_loss: 0.4430\n",
      "Epoch 28/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 4ms/step - accuracy: 0.7667 - auc: 0.8688 - loss: 0.4415 - val_accuracy: 0.7649 - val_auc: 0.8673 - val_loss: 0.4441\n",
      "Epoch 29/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 4ms/step - accuracy: 0.7664 - auc: 0.8687 - loss: 0.4414 - val_accuracy: 0.7644 - val_auc: 0.8680 - val_loss: 0.4419\n",
      "Epoch 30/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 3ms/step - accuracy: 0.7666 - auc: 0.8692 - loss: 0.4412 - val_accuracy: 0.7641 - val_auc: 0.8682 - val_loss: 0.4424\n",
      "Epoch 31/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 4ms/step - accuracy: 0.7689 - auc: 0.8705 - loss: 0.4397 - val_accuracy: 0.7655 - val_auc: 0.8680 - val_loss: 0.4428\n",
      "Epoch 32/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7683 - auc: 0.8703 - loss: 0.4405 - val_accuracy: 0.7663 - val_auc: 0.8691 - val_loss: 0.4405\n",
      "Epoch 33/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 3ms/step - accuracy: 0.7690 - auc: 0.8699 - loss: 0.4404 - val_accuracy: 0.7675 - val_auc: 0.8685 - val_loss: 0.4419\n",
      "Epoch 34/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7688 - auc: 0.8708 - loss: 0.4402 - val_accuracy: 0.7677 - val_auc: 0.8695 - val_loss: 0.4416\n",
      "Epoch 35/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7688 - auc: 0.8712 - loss: 0.4383 - val_accuracy: 0.7666 - val_auc: 0.8700 - val_loss: 0.4396\n",
      "Epoch 36/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7705 - auc: 0.8717 - loss: 0.4384 - val_accuracy: 0.7677 - val_auc: 0.8703 - val_loss: 0.4400\n",
      "Epoch 37/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7690 - auc: 0.8718 - loss: 0.4373 - val_accuracy: 0.7654 - val_auc: 0.8689 - val_loss: 0.4426\n",
      "Epoch 38/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7704 - auc: 0.8724 - loss: 0.4375 - val_accuracy: 0.7683 - val_auc: 0.8695 - val_loss: 0.4404\n",
      "Epoch 39/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7706 - auc: 0.8726 - loss: 0.4380 - val_accuracy: 0.7676 - val_auc: 0.8695 - val_loss: 0.4416\n",
      "Epoch 40/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7694 - auc: 0.8722 - loss: 0.4381 - val_accuracy: 0.7667 - val_auc: 0.8703 - val_loss: 0.4389\n",
      "Epoch 41/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7711 - auc: 0.8731 - loss: 0.4358 - val_accuracy: 0.7655 - val_auc: 0.8702 - val_loss: 0.4400\n",
      "Epoch 42/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7733 - auc: 0.8741 - loss: 0.4352 - val_accuracy: 0.7662 - val_auc: 0.8712 - val_loss: 0.4383\n",
      "Epoch 43/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 4ms/step - accuracy: 0.7724 - auc: 0.8739 - loss: 0.4355 - val_accuracy: 0.7662 - val_auc: 0.8706 - val_loss: 0.4395\n",
      "Epoch 44/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7723 - auc: 0.8744 - loss: 0.4341 - val_accuracy: 0.7636 - val_auc: 0.8699 - val_loss: 0.4410\n",
      "Epoch 45/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7713 - auc: 0.8740 - loss: 0.4354 - val_accuracy: 0.7666 - val_auc: 0.8712 - val_loss: 0.4389\n",
      "Epoch 46/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7727 - auc: 0.8741 - loss: 0.4348 - val_accuracy: 0.7679 - val_auc: 0.8714 - val_loss: 0.4393\n",
      "Epoch 47/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7731 - auc: 0.8744 - loss: 0.4340 - val_accuracy: 0.7661 - val_auc: 0.8698 - val_loss: 0.4396\n",
      "Epoch 48/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7730 - auc: 0.8750 - loss: 0.4343 - val_accuracy: 0.7683 - val_auc: 0.8705 - val_loss: 0.4384\n",
      "Epoch 49/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7743 - auc: 0.8757 - loss: 0.4337 - val_accuracy: 0.7680 - val_auc: 0.8707 - val_loss: 0.4399\n",
      "Epoch 50/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7738 - auc: 0.8759 - loss: 0.4331 - val_accuracy: 0.7679 - val_auc: 0.8714 - val_loss: 0.4390\n",
      "Epoch 51/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 4ms/step - accuracy: 0.7748 - auc: 0.8759 - loss: 0.4342 - val_accuracy: 0.7677 - val_auc: 0.8724 - val_loss: 0.4382\n",
      "Epoch 52/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7757 - auc: 0.8761 - loss: 0.4337 - val_accuracy: 0.7683 - val_auc: 0.8711 - val_loss: 0.4391\n",
      "Epoch 53/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 3ms/step - accuracy: 0.7752 - auc: 0.8759 - loss: 0.4336 - val_accuracy: 0.7687 - val_auc: 0.8720 - val_loss: 0.4391\n",
      "Epoch 54/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 4ms/step - accuracy: 0.7739 - auc: 0.8754 - loss: 0.4340 - val_accuracy: 0.7694 - val_auc: 0.8719 - val_loss: 0.4375\n",
      "Epoch 55/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 4ms/step - accuracy: 0.7740 - auc: 0.8754 - loss: 0.4343 - val_accuracy: 0.7673 - val_auc: 0.8723 - val_loss: 0.4382\n",
      "Epoch 56/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 4ms/step - accuracy: 0.7742 - auc: 0.8758 - loss: 0.4343 - val_accuracy: 0.7690 - val_auc: 0.8722 - val_loss: 0.4380\n",
      "Epoch 57/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 3ms/step - accuracy: 0.7755 - auc: 0.8767 - loss: 0.4326 - val_accuracy: 0.7704 - val_auc: 0.8721 - val_loss: 0.4390\n",
      "Epoch 58/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7739 - auc: 0.8757 - loss: 0.4336 - val_accuracy: 0.7680 - val_auc: 0.8709 - val_loss: 0.4412\n",
      "Epoch 59/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7760 - auc: 0.8784 - loss: 0.4295 - val_accuracy: 0.7704 - val_auc: 0.8716 - val_loss: 0.4390\n",
      "Epoch 60/60\n",
      "\u001B[1m2449/2449\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 3ms/step - accuracy: 0.7755 - auc: 0.8762 - loss: 0.4334 - val_accuracy: 0.7693 - val_auc: 0.8720 - val_loss: 0.4388\n",
      "\u001B[1m766/766\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step\n",
      "Accuracy : 76.90%\n",
      "AUC ROC  : 0.8730\n",
      "Loss     : 0.4361\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
